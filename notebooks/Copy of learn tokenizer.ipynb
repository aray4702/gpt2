{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4928,"status":"ok","timestamp":1744309680566,"user":{"displayName":"test user1","userId":"00789796017718277410"},"user_tz":420},"id":"dr3wLV_JyPwO","outputId":"07e02a5a-91dc-4998-e597-c14d55e6b42b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tiktoken\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n","Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.9.0\n"]}],"source":["!pip install tiktoken"]},{"cell_type":"code","execution_count":132,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69v1C9REzX-n","executionInfo":{"status":"ok","timestamp":1744318155569,"user_tz":420,"elapsed":18,"user":{"displayName":"test user1","userId":"00789796017718277410"}},"outputId":"9334fc44-bc9b-4093-ae04-d60bb8400300"},"outputs":[{"output_type":"stream","name":"stdout","text":["text: do you still remember the day of world david...\n","make token for  ((5, 10), 2)\n","make token for  ((0, 4), 2)\n","make token for  ((20, 2), 2)\n","make token for  ((1, 1), 2)\n","a2t {' ': 0, '.': 1, 'a': 2, 'b': 3, 'd': 4, 'e': 5, 'f': 6, 'h': 7, 'i': 8, 'l': 9, 'm': 10, 'o': 11, 'r': 12, 's': 13, 't': 14, 'u': 15, 'v': 16, 'w': 17, 'y': 18}\n","t2a {0: ' ', 1: '.', 2: 'a', 3: 'b', 4: 'd', 5: 'e', 6: 'f', 7: 'h', 8: 'i', 9: 'l', 10: 'm', 11: 'o', 12: 'r', 13: 's', 14: 't', 15: 'u', 16: 'v', 17: 'w', 18: 'y'}\n","t2p {0: (0,), 1: (1,), 2: (2,), 3: (3,), 4: (4,), 5: (5,), 6: (6,), 7: (7,), 8: (8,), 9: (9,), 10: (10,), 11: (11,), 12: (12,), 13: (13,), 14: (14,), 15: (15,), 16: (16,), 17: (17,), 18: (18,), 19: (5, 10), 20: (0, 4), 21: (20, 2), 22: (1, 1)}\n","p2t {(0,): 0, (1,): 1, (2,): 2, (3,): 3, (4,): 4, (5,): 5, (6,): 6, (7,): 7, (8,): 8, (9,): 9, (10,): 10, (11,): 11, (12,): 12, (13,): 13, (14,): 14, (15,): 15, (16,): 16, (17,): 17, (18,): 18, (5, 10): 19, (0, 4): 20, (20, 2): 21, (1, 1): 22}\n","encode result: [4, 11, 0, 18, 11, 15, 0, 13, 14, 8, 9, 9, 0, 12, 19, 19, 3, 5, 12, 0, 14, 7, 5, 21, 18, 0, 11, 6, 0, 17, 11, 12, 9, 4, 21, 16, 8, 4, 22, 1]\n","47 -> 40\n","decode result: do you still remember the day of world david...\n"]}],"source":["''' bpe design\n","   letter table {token: <letter>}\n","   token table {token: (token1, token2)}\n","\n","train:\n","   most frequent token pair\n","   if pair count >= min_count and token table size < max_tokens\n","      create new token for the pair\n","   if new token is not empty\n","      for each pair in sequence\n","          replace pair with new token\n","      add new token to token table\n","   else\n","      break\n","\n","encode:\n","  convert sequence to token sequence\n","  do\n","    for each pair in sequence:\n","      replace pair with token if found in token table\n","  until no pairs can be tokenized\n","\n","decode:\n","  do\n","    for each token in sequence\n","      replace with pair\n","  until no token can be decoded\n","'''\n","import tiktoken\n","import heapq\n","\n","enc = tiktoken.get_encoding('gpt2')\n","len(enc.encode('bpe'))\n","\n","words = 'do you still remember the day of world david...'\n","letters = list(sorted(set(words)))\n","\n","# vocab\n","a2t = {ch:token for token,ch in enumerate(letters)}\n","t2a = {token:ch for ch,token in a2t.items()}\n","t2p= {token:(token,) for token,_ in t2a.items()}\n","p2t= {}\n","\n","\n","# train\n","data = [a2t[ch] for ch in words]\n","def count_pairs(data):\n","  counter = dict()\n","  for i in range(len(data)-1):\n","    pair = (data[i],data[i+1])\n","    if pair in counter:\n","      counter[pair] += 1\n","    else:\n","      counter[pair] = 1\n","\n","  if len(counter) == 0:\n","    return None\n","  else:\n","    return heapq.nlargest(1, counter.items(), lambda x:x[1])[-1]\n","\n","min_count = 2\n","max_tokens = 100\n","\n","# train\n","def train(data):\n","  global p2t\n","  while True:\n","    pair = count_pairs(data)\n","    if pair is None or pair[1] < min_count or len(ttot) >= max_tokens:\n","      break\n","    else:\n","      print('make token for ', pair)\n","      token = len(t2p)\n","      t2p[token] = pair[0]\n","      new_data = []\n","      pos = 0\n","      while pos < len(data) - 1:\n","        if data[pos] == pair[0][0] and data[pos+1] == pair[0][1]:\n","          new_data.append(token)\n","          pos += 2\n","        else:\n","          new_data.append(data[pos])\n","          pos += 1\n","      if pos < len(data):\n","        new_data.append(data[pos])\n","      data = new_data\n","    p2t = {pair:token for token,pair in t2p.items()}\n","\n","# encode\n","def encode(text):\n","  ''' given atot and ttot, convert text to token sequence'''\n","  tokens = [a2t[ch] for ch in text]\n","  while True:\n","    new_tokens = []\n","    pos = 0\n","    while pos < len(tokens) - 1:\n","      if (tokens[pos], tokens[pos+1]) in p2t:\n","        #print('replace', (tokens[pos], tokens[pos+1]), 'with', p2t[(tokens[pos], tokens[pos+1])])\n","        new_tokens.append(p2t[(tokens[pos], tokens[pos+1])])\n","        pos += 2\n","      else:\n","        new_tokens.append(tokens[pos])\n","        pos += 1\n","    if pos < len(tokens):\n","      new_tokens.append(tokens[pos])\n","    if len(new_tokens) == len(tokens):\n","      break\n","    else:\n","      tokens = new_tokens\n","\n","  return tokens\n","\n","# decode\n","def decode(tokens):\n","  while True:\n","    i = 0\n","    new_tokens = []\n","    for token in tokens:\n","      i += 1\n","      if i > 100:\n","        break\n","      if token in t2p:\n","        new_tokens.append(t2p[token][0])\n","        if len(t2p[token]) == 2:\n","          new_tokens.append(t2p[token][1])\n","    if len(new_tokens) == len(tokens):\n","      break\n","    else:\n","      tokens = new_tokens\n","  return ''.join([t2a[token] for token in tokens])\n","\n","# test\n","text = words\n","print('text:', text)\n","train(data)\n","\n","print('a2t',a2t)\n","print('t2a',t2a)\n","print('t2p',t2p)\n","print('p2t',p2t)\n","\n","tokens = encode(text)\n","print('encode result:',tokens)\n","print(len(text),'->', len(tokens))\n","print('decode result:', decode(tokens))\n"]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1744317721679,"user":{"displayName":"test user1","userId":"00789796017718277410"},"user_tz":420},"id":"K2nNjPmKzvKx","outputId":"3dbb85a6-c6c4-4863-babe-9439d94574c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["None\n","2\n","[] 134630373861888\n","[3] 134630373861888\n","1\n","arr: [1, 2, 3]\n","arr: 7\n","arr: 8\n","arr: 9\n"]}],"source":["import heapq\n","\n","heapq.nlargest(1, [1,3,5,7], lambda x:-x)\n","i=0\n","while i < 0:\n","  print(i)\n","  i+=1\n","\n","\n","min_count = 2\n","def train(data):\n","  print(data)\n","  #min_count +=1\n","  print(min_count)\n","\n","train(None)\n","\n","min_count=[]\n","def bar(data):\n","  print(min_count, id(min_count))\n","  min_count.append(3)\n","  print(min_count, id(min_count))\n","\n","bar(None)\n","print(foo)\n","\n","def test(arr):\n","  print('arr:',arr)\n","  arr = [7,8,9]\n","  for i in arr:\n","    print('arr:',i)\n","\n","test([1,2,3])\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"13KfeTsAEDyHDc7qCxwv-1DNwWHuVxJ5K","timestamp":1744318306552}],"authorship_tag":"ABX9TyP78PqIE//zc99jUjPS4p5e"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}